# ğŸš€ Teste RÃ¡pido v3 - VersÃ£o OTIMIZADA

## âš¡ O Que Mudou

### v2 â†’ v3 Melhorias:

**1. CatÃ¡logo Expandido** âœ…
- v2: 7 clÃ¡usulas
- v3: **25 clÃ¡usulas** (cobertura completa)

**2. Performance** âœ…
- v2: ~30 minutos (1827s)
- v3: **~5-7 minutos** (meta: 5-10x mais rÃ¡pido)

**3. Prompts Otimizados** âœ…
- ReduÃ§Ã£o de 60% no tamanho
- Truncamento inteligente de conteÃºdo
- NÃºmero de tokens previsÃ­veis reduzido

**4. Matching Melhorado** âœ…
- Regex patterns mais precisos
- Keywords alinhadas com documento real
- 25 IDs especÃ­ficos de clÃ¡usulas

## ğŸ§ª Como Testar

### Comando de Teste (SEM CUSTO)

```bash
cd juridico-review-ai

python src/main_v3.py \
  --minuta "data/entrada/CRI Evoke_TS_v.02  07102025_001_22063v5.DOCX" \
  --catalogo data/catalogos/catalogo_cri_v3.yaml \
  --skip-tier2 \
  --verbose
```

### O que esperar:

**Tempo estimado:** 5-7 minutos (vs 30min na v2)

**MÃ©tricas esperadas:**
- Parsing: <1s
- Ranking: ~10s
- ClassificaÃ§Ã£o Tier-1: **5-7min** (~15-20s por clÃ¡usula)
- Total: ~7min

**Resultados esperados:**
- âœ… Mais clÃ¡usulas PRESENTES (catÃ¡logo expandido)
- âœ… Matching mais preciso
- âœ… Menos falsos negativos

## ğŸ“Š ComparaÃ§Ã£o v2 vs v3

| MÃ©trica | v2 (Teste Anterior) | v3 (Esperado) |
|---------|---------------------|---------------|
| **Tempo Total** | 30min 39s | ~7min |
| **ClÃ¡usulas CatÃ¡logo** | 7 | 25 |
| **PRESENTES** | 0 | 8-12 |
| **PARCIAIS** | 2 | 5-8 |
| **AUSENTES** | 18 | 2-5 |
| **Performance** | 1x | **5-7x mais rÃ¡pido** |

## ğŸ¯ Checklist de ValidaÃ§Ã£o

ApÃ³s rodar o teste, verifique:

- [ ] Tempo total < 10 minutos
- [ ] Pelo menos 50% das clÃ¡usulas como PRESENTE ou PARCIAL
- [ ] Excel gerado com 4 abas
- [ ] DOCX narrativo criado
- [ ] Audit JSON com metadados completos
- [ ] Menos de 5 clÃ¡usulas totalmente AUSENTES

## ğŸ” Analisando Resultados

### 1. Excel - Aba "Resumo"
Verifique se os nÃºmeros fazem sentido:
- Total de clÃ¡usulas analisadas: 20
- ClÃ¡usulas OK (Tier-1): deve ser > 0
- PRESENTES: esperamos 8-12

### 2. Excel - Aba "ClÃ¡usulas OK"
Veja quais foram aprovadas no Tier-1

### 3. Excel - Aba "SugestÃµes"
Identifique quais clÃ¡usulas precisam melhoria

### 4. Audit JSON
```bash
# Ver sumÃ¡rio rÃ¡pido
python -c "
import json
with open('data/saida/audit_*.json') as f:
    a = json.load(f)
    print('Tempo total:', a['metadata']['tempo_total_segundos'], 's')
    print('Tier-1:', a['metadata']['tier1']['summary'])
"
```

## ğŸ› Se Algo Der Errado

### Erro: "Module not found"
```bash
pip install -r requirements.txt
```

### Muito lento ainda (>15min)
- Verifique se Ollama estÃ¡ usando GPU
- Tente modelo menor: `--tier1-model qwen2:1.5b`

### Todos classificados como AUSENTE
- O catÃ¡logo v3 deve resolver isso
- Verifique se estÃ¡ usando catalogo_cri_v3.yaml

### Erro de memÃ³ria
- Reduza `--top-k` para 1
- Use modelo menor

## ğŸ“ Logs Ãšteis

Com `--verbose`, vocÃª verÃ¡:
```
[1/20] Classificando: DEFINIÃ‡Ã•ES...
[2/20] Classificando: APROVAÃ‡ÃƒO DA EMISSÃƒO...
...
```

Isso ajuda a acompanhar o progresso em tempo real.

## âœ… Teste Bem-Sucedido Se:

1. âœ… Terminou em < 10 minutos
2. âœ… Pelo menos 10 clÃ¡usulas como PRESENTE
3. âœ… Excel e DOCX gerados corretamente
4. âœ… Matching correto das clÃ¡usulas principais:
   - DefiniÃ§Ãµes â†’ CRI_DEF_001
   - RemuneraÃ§Ã£o â†’ CRI_REM_001
   - Agente FiduciÃ¡rio â†’ CRI_AGF_001
   - Assembleia â†’ CRI_ASS_001

## ğŸ”„ PrÃ³ximos Passos se v3 Funcionar

1. **Testar Tier-2** (remover `--skip-tier2`)
2. **Criar catÃ¡logos CRA e DebÃªntures v3**
3. **Fine-tune do modelo** para melhor precisÃ£o
4. **Cache persistente** de embeddings
5. **Interface web** simples

## ğŸ’¬ Feedback

ApÃ³s o teste, documente:
- Tempo real gasto
- Quantidade de PRESENTE/PARCIAL/AUSENTE
- Falsos positivos/negativos
- SugestÃµes de melhoria

---

**VersÃ£o**: 3.0.0
**Data**: 2025-10-16
**Status**: Pronto para teste
